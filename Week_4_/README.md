Create a mini RAG pipeline: 5–10 docs → embeddings → query → LLM answer.
Outcome: Build first small LLM pipeline.